#from AnalyticsPipeline.video_utils import FileVideoStream, OutputVideoStream
from torchinfo import summary
import time
import os.path as osp
import os
import utils
import dataset_utils as du
import logging
import cv2
import traceback
import matplotlib.pyplot as plt
import pandas as pd
from collections import defaultdict
from segmentation_models_pytorch.utils.functional import iou
import torch
logger = logging.getLogger(__name__)


class TennisExploitation:
    def __init__(self,
                 model,
                 dataset,
                 experiment_id,
                 dataset_name,
                 exploitation_name,
                 input_height,
                 input_width,
                 experiment_path,
                 overlay_opacity
                 ):
        self.model = model
        self.dataset = dataset
        self.experiment_id = experiment_id
        self.dataset_name = dataset_name
        self.exploitation_name = exploitation_name
        self.input_height = input_height
        self.input_width = input_width
        self.experiment_path = experiment_path
        self.overlay_opacity = overlay_opacity

        self.logfilehandler = logging.FileHandler(osp.join(experiment_path, "logs","exploitation_output.log"), 'a')
        self.logfilehandler.setFormatter(logging.Formatter('%(asctime)s: %(message)s'))
        logger.addHandler(self.logfilehandler)
        logger.info("-"*40)
        logger.info(self.__class__.__name__ + " instance created")

    def prepare_exploitation(self):
        #self.videos_output_dir = osp.join(self.experiment_path, 'Videos')
        #utils.create_folder(self.videos_output_dir)

        self.samples_output_dir = osp.join(self.experiment_path, 'Samples')
        utils.create_folder(self.samples_output_dir)
        utils.create_folder(osp.join(self.samples_output_dir,'train'))
        utils.create_folder(osp.join(self.samples_output_dir, 'valid'))
        #utils.create_folder(osp.join(self.samples_output_dir, 'test'))
        ##image output
        logger.info("Output folders created")

    def generate_outputs(self):
        self.create_model_summary()
        self.visualize_training_graphs()
        self.visualize_training_iter_graphs()
        self.save_training_data()
        self.generate_samples()
        #self.make_videos()

    def save_training_data(self):
        train_df = pd.DataFrame(self.model.train_logs_list)
        train_df = train_df.add_prefix('train_')
        valid_df = pd.DataFrame(self.model.valid_logs_list)
        valid_df = valid_df.add_prefix('valid_')

        train_valid_df = pd.concat([train_df, valid_df], axis=1)
        train_valid_df.to_csv(osp.join(self.experiment_path,"training_validation_data.csv"), index=False)

    def generate_samples(self):
        inference_times = []
        #miou_columns=dict({'partition':'str'},**{c+'_miou':'float' for c in self.dataset.class_names})
        miou_columns = dict({'image_id': 'int','partition': 'str'}, **{c: 'float' for c in self.dataset.class_names})
        miou_df = pd.DataFrame({c: pd.Series(dtype=t) for c,t in miou_columns.items()})
        train_valid_test=[('train',self.dataset.x_train_dir,self.dataset.y_train_dir),
                          ('valid',self.dataset.x_valid_dir,self.dataset.y_valid_dir)
                          #('test',self.dataset.x_test_dir,self.dataset.y_test_dir)
                          ]
        for dataset in train_valid_test:
            logger.info("")
            logger.info(f"Generating {dataset[0]} samples")
            for image_filename in os.listdir(dataset[1]):
                image = cv2.cvtColor(cv2.imread(osp.join(dataset[1],image_filename)), cv2.COLOR_BGR2RGB)
                gt_mask = cv2.cvtColor(cv2.imread(osp.join(dataset[2], image_filename)), cv2.COLOR_BGR2RGB)
                image_vis = cv2.resize(image, (self.input_width, self.input_height))
                gt_mask_vis = du.one_hot_encode(gt_mask, len(self.dataset))
                gt_mask_tensor = torch.from_numpy(utils.to_tensor(gt_mask_vis)).to(self.model.device).unsqueeze(0)

                inference_start_time = time.time()
                pred_mask_tensor = self.model.inference(image)
                pred_mask = self.model.post_processing(pred_mask_tensor)
                inference_times.append(time.time() - inference_start_time)

                pred_mask_overlay = utils.generate_overlay(pred_mask, image_vis, self.overlay_opacity,
                                                     self.dataset.colour_palette)

                gt_mask_vis_overlay = utils.generate_overlay(utils.reverse_one_hot(gt_mask_vis),
                                                                 image_vis, self.overlay_opacity,
                                                                 self.dataset.colour_palette)

                fp_mask_overlay = utils.generate_mask_fp(pred_mask,utils.reverse_one_hot(gt_mask_vis),image_vis, self.overlay_opacity,
                                                     self.dataset.colour_palette[:])

                final_image=utils.concat_images([[image_vis,gt_mask_vis_overlay],[pred_mask_overlay,fp_mask_overlay]])
                save_path=osp.join(self.samples_output_dir,dataset[0],image_filename)
                cv2.imwrite(save_path,cv2.cvtColor(final_image, cv2.COLOR_RGB2BGR))
                miou_partition = defaultdict(float)

                for i,c in enumerate(self.dataset.class_names):
                    miou_partition[c]=iou(pred_mask_tensor,gt_mask_tensor,ignore_channels=[n for n in range(self.dataset.n_classes) if n != i]).detach().squeeze().cpu().numpy()
                miou_df = miou_df.append(dict({'image_id': image_filename[:-4], 'partition': dataset[0]}, **miou_partition), ignore_index=True)


        self.inference_time=sum(inference_times[1:])/(len(inference_times)-1)
        self.inference_gpu_usage=utils.get_gpu_memory()
        logger.info(f"Mean inference gpu time: {self.inference_time}")
        logger.info(f"Inference gpu usage: {self.inference_gpu_usage} MB")
        miou_df.to_csv(osp.join(self.experiment_path,"iou_per_class.csv"), index=False)

    def visualize_training_graphs(self):
        px = 1 / plt.rcParams['figure.dpi']
        metrics=["WeightedDiceLoss","iou_score"]
        train_df = pd.DataFrame(self.model.train_logs_list)
        valid_df = pd.DataFrame(self.model.valid_logs_list)
        fig, axes = plt.subplots(1, len(metrics), figsize=(1000 * len(metrics) * px, 800 * px))
        for i, metric in enumerate(metrics):
            axes[i].plot(train_df.index.tolist(), train_df[metric].tolist(), lw=2, label='Train')
            axes[i].plot(valid_df.index.tolist(), valid_df[metric].tolist(), lw=2, label='Valid')
            axes[i].set_xlabel('Epochs', fontsize=20)
            axes[i].set_ylabel(metric.capitalize(), fontsize=20)
            axes[i].legend(loc='best', fontsize=16)
            axes[i].grid()
            axes[i].set_title(metric.capitalize() + ' Plot', fontsize=20)
        plt.savefig(osp.join(self.experiment_path,"training_graph_plot.png"))
        logger.info(f"Saved graph plots of training and validation")

    def visualize_training_iter_graphs(self):
        px = 1 / plt.rcParams['figure.dpi']
        metrics=["WeightedDiceLoss","iou_score"]
        train_df = pd.DataFrame(self.model.train_logs_iter_list)
        valid_df = pd.DataFrame(self.model.valid_logs_iter_list)
        fig, axes = plt.subplots(2, len(metrics), figsize=(1000 * len(metrics) * px, 1600 * px))
        for i, metric in enumerate(metrics):
            axes[0,i].plot(train_df.index.tolist(), train_df[metric].tolist(), lw=2, label='Train')
            axes[0,i].set_xlabel('Iterations', fontsize=20)
            axes[0,i].set_ylabel(metric.capitalize(), fontsize=20)
            axes[0,i].legend(loc='best', fontsize=16)
            axes[0,i].grid()
            axes[0,i].set_title(metric.capitalize() + ' Plot', fontsize=20)
            axes[1, i].plot(valid_df.index.tolist(), valid_df[metric].tolist(), lw=2, label='Valid')
            axes[1, i].set_xlabel('Iterations', fontsize=20)
            axes[1, i].set_ylabel(metric.capitalize(), fontsize=20)
            axes[1, i].legend(loc='best', fontsize=16)
            axes[1, i].grid()
            axes[1, i].set_title(metric.capitalize() + ' Plot', fontsize=20)
        plt.savefig(osp.join(self.experiment_path,"training_graph_iter_plot.png"))
        logger.info(f"Saved graph iteration plots of training and validation")

    def make_videos(self, verbose=False):
        fps_list=[]
        elapsed_time_list = []

        for filename in os.listdir(self.test_vids_path):
            logger.info("")
            logger.info(f"Processing video {osp.basename(filename)}")
            video_path=osp.join(self.test_vids_path,filename)
            output_vid_path = osp.join(self.videos_output_dir, filename)
            output_text = os.path.join(self.videos_output_dir, "video_results.txt")
            fvs = FileVideoStream(video_path).start()
            frame_width, frame_height, fps = int(fvs.stream.get(3)), int(fvs.stream.get(4)), float(fvs.stream.get(5))
            ovs = OutputVideoStream(output_vid_path, fps, frame_width, frame_height).start()
            n_frames = 0
            total_frames = int(fvs.stream.get(cv2.CAP_PROP_FRAME_COUNT))
            fps_frames = []
            start_time = time.time()
            prev_frame_time = 0
            overlaytime = 0
            try:
                while fvs.more():
                    new_frame_time = time.time()
                    fps = 1 / (new_frame_time - prev_frame_time)
                    if n_frames>2 and n_frames<total_frames-2:
                        fps_frames.append(fps)
                    if verbose and n_frames % 5 == 0:
                        print(f"Progress: {n_frames}/{total_frames}")
                        print("Fps: {:.2f}".format(fps))
                        print("Input queue size:", fvs.Q.qsize())
                        print("Output queue size:", ovs.Q.qsize())
                        print("Time spent:", time.time() - prev_frame_time)
                        print("-" * 20)
                    prev_frame_time = new_frame_time

                    image = fvs.read()

                    if image is None and not fvs.more():
                        fvs.stop()
                        break

                    pred_mask = self.model.inference(image)
                    pred_mask = self.model.post_processing(pred_mask)
                    image_vis = cv2.resize(image, (self.input_width, self.input_height))

                    overlay_start_time = time.time()
                    final_image = utils.generate_overlay(pred_mask, image_vis, self.overlay_opacity, self.dataset.colour_palette)
                    overlaytime += time.time() - overlay_start_time

                    final_image = cv2.resize(final_image, (frame_width, frame_height))
                    ovs.save(final_image)
                    n_frames += 1

            except (Exception, KeyboardInterrupt):
                ovs.stop()
                fvs.stop()
                logger.error(traceback.format_exc())
                logger.error(f"Error while processing video {filename}")
                raise Exception("shit")

            elapsed_time_list.append(time.time() - start_time)
            fps_list.append(sum(fps_frames[1:]) / (len(fps_frames)-1))

            with open(output_text, "a+") as f:
                f.write(f"VIDEO_NAME= {osp.basename(video_path)}\n")
                f.write("Elasped time: {:.2f}\n".format(elapsed_time_list[-1]))
                f.write("Overlay time: {:.2f}\n".format(overlaytime))
                f.write("Approx. FPS: {:.2f}\n".format(n_frames / (time.time() - start_time)))
                f.write(
                    "Aprox. FPS without overlay: {:.2f}\n".format(fps_list[-1]))
                f.write("-" * 30 + "\n")
            logger.info("Elasped time: {:.2f}".format(elapsed_time_list[-1]))

            ovs.stop()
            fvs.stop()

        self.video_elapsed_time = sum(elapsed_time_list)/len(elapsed_time_list)
        self.video_fps = sum(fps_list) / len(fps_list)

    def create_model_summary(self):
        output_text = os.path.join(self.experiment_path, "model_summary.txt")
        with open(output_text, "a+", encoding='utf-8') as f:
            f.write(str(summary(self.model.model, input_size=(self.model.batch_size, 3, self.input_height, self.input_width), verbose=True)))
        logger.info("Model summary created")

    def get_results(self, config):
        self.model.get_results(config)
        config["video_fps"]=self.video_fps
        config["video_elapsed_time"] = self.video_elapsed_time
        config["inference_time"] = self.inference_time
        config["inference_gpu_usage"] = self.inference_gpu_usage
        logger.info("")
        logger.info("All results have been extracted")

    def __del__(self):
        logger.removeHandler(self.logfilehandler)

class SemanticsegmentationExploitation(TennisExploitation):
    def __init__(self, model, dataset, **kwargs):
        super().__init__(model,dataset, **kwargs)
